"""
Main document ingestion script to process all documents and store in vector database.
"""
import sys
import os
from pathlib import Path

# Add project root to path
project_root = Path(__file__).parent.parent.parent
sys.path.append(str(project_root))

from loguru import logger
from src.utils.config_manager import ConfigManager
from src.ingestion.document_processor import UniversalDocumentProcessor
from src.ingestion.vector_db_manager import VectorDBFactory


def setup_logging():
    """Setup logging configuration."""
    logger.remove()  # Remove default handler
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level="INFO"
    )
    
    # Create logs directory if it doesn't exist
    logs_dir = Path("logs")
    logs_dir.mkdir(exist_ok=True)
    
    logger.add(
        "logs/ingestion.log",
        format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
        level="DEBUG",
        rotation="10 MB"
    )


def main():
    """Main ingestion process."""
    setup_logging()
    logger.info("ðŸ¥ Starting Universal RAG Document Ingestion")
    logger.info("=" * 60)
    
    try:
        # Load configuration
        config = ConfigManager()
        
        # Validate configuration
        if not config.validate_config():
            logger.error("âŒ Configuration validation failed")
            return False
        
        # Create necessary directories
        config.create_directories()
        
        # Initialize document processor
        logger.info("ðŸ“„ Initializing Universal Document Processor...")
        doc_processor = UniversalDocumentProcessor(config)
        
        # Initialize vector database
        logger.info("ðŸ—ƒï¸ Initializing Vector Database...")
        vector_db = VectorDBFactory.create_vector_db(config)
        
        # Check current database stats
        current_stats = vector_db.get_collection_stats()
        logger.info(f"ðŸ“Š Current database stats: {current_stats}")
        
        # Process all documents
        logger.info("ðŸ”„ Processing documents...")
        all_metadata, all_chunks = doc_processor.process_all_documents()
        
        if not all_chunks:
            logger.warning("âš ï¸ No documents were processed successfully")
            return False
        
        # Store in vector database
        logger.info(f"ðŸ’¾ Storing {len(all_chunks)} chunks in vector database...")
        vector_db.add_documents(all_chunks)
        
        # Final stats
        final_stats = vector_db.get_collection_stats()
        logger.info(f"ðŸ“Š Final database stats: {final_stats}")
        
        # Summary
        logger.info("=" * 60)
        logger.info("âœ… INGESTION COMPLETED SUCCESSFULLY!")
        logger.info(f"ðŸ“ Documents processed: {len(all_metadata)}")
        logger.info(f"ðŸ“„ Total chunks created: {len(all_chunks)}")
        logger.info(f"ðŸ—ƒï¸ Vector database: {vector_db.__class__.__name__}")
        
        # Document breakdown
        doc_types = {}
        chunk_counts = {}
        for metadata in all_metadata:
            doc_type = metadata.file_type.value
            doc_types[doc_type] = doc_types.get(doc_type, 0) + 1
            chunk_counts[doc_type] = chunk_counts.get(doc_type, 0) + metadata.chunk_count
        
        logger.info("ðŸ“‹ Document breakdown:")
        for doc_type, count in doc_types.items():
            logger.info(f"   {doc_type.upper()}: {count} files, {chunk_counts[doc_type]} chunks")
        
        logger.info("ðŸš€ Ready for RAG queries!")
        logger.info("ðŸ’¡ Next step: Build the Streamlit interface")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ingestion failed: {str(e)}")
        import traceback
        logger.error(traceback.format_exc())
        return False


def check_data_availability():
    """Check if source data is available."""
    config = ConfigManager()
    data_source_paths = config.get_data_source_paths()
    
    total_files = 0
    for format_name, path in data_source_paths.items():
        if os.path.exists(path):
            files = list(Path(path).glob("*"))
            file_count = len([f for f in files if f.is_file()])
            total_files += file_count
            logger.info(f"ðŸ“ {format_name.upper()}: {file_count} files in {path}")
        else:
            logger.warning(f"âš ï¸ Directory not found: {path}")
    
    if total_files == 0:
        logger.error("âŒ No source files found! Please add documents to data_source/ directories")
        logger.info("ðŸ’¡ Expected structure:")
        logger.info("   data_source/pdf/     - PDF files")
        logger.info("   data_source/docx/    - Word documents")
        logger.info("   data_source/txt/     - Text files")
        logger.info("   data_source/csv/     - CSV files")
        return False
    
    logger.info(f"âœ… Found {total_files} total files to process")
    return True


def reset_database():
    """Reset the vector database (useful for development)."""
    logger.warning("ðŸ—‘ï¸ Resetting vector database...")
    
    config = ConfigManager()
    vector_db = VectorDBFactory.create_vector_db(config)
    
    try:
        if hasattr(vector_db, 'delete_collection'):
            vector_db.delete_collection()
            logger.info("âœ… Database reset completed")
        else:
            logger.warning("âš ï¸ Database reset not supported for this vector DB type")
    except Exception as e:
        logger.error(f"âŒ Error resetting database: {str(e)}")


def show_help():
    """Show help information."""
    print("""
ðŸ¥ Universal RAG Document Ingestion Tool

Usage:
    python src/ingestion/ingest_documents.py [options]

Options:
    --check     Check data availability only
    --reset     Reset vector database before ingestion
    --help      Show this help message

Examples:
    python src/ingestion/ingest_documents.py           # Normal ingestion
    python src/ingestion/ingest_documents.py --check   # Check files only
    python src/ingestion/ingest_documents.py --reset   # Reset DB and ingest

Requirements:
    - GOOGLE_API_KEY in environment variables
    - Documents in data_source/ subdirectories
    - Valid config/config.yaml file
    """)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Universal RAG Document Ingestion")
    parser.add_argument("--reset", action="store_true", help="Reset vector database before ingestion")
    parser.add_argument("--check", action="store_true", help="Only check data availability")
    parser.add_argument("--help-full", action="store_true", help="Show detailed help")
    
    args = parser.parse_args()
    
    if args.help_full:
        show_help()
    elif args.check:
        setup_logging()
        check_data_availability()
    elif args.reset:
        setup_logging()
        reset_database()
        if check_data_availability():
            main()
        else:
            logger.error("âŒ Cannot proceed without source data")
            sys.exit(1)
    else:
        setup_logging()
        if check_data_availability():
            main()
        else:
            logger.error("âŒ Cannot proceed without source data")
            sys.exit(1)